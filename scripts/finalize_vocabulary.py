"""
è¯è¡¨æœ€ç»ˆå½’æ¡£è„šæœ¬
å°†v1.3è®¾ä¸ºæ­£å¼ç‰ˆæœ¬ï¼Œæ¸…ç†ä¸­é—´æ–‡ä»¶ï¼Œç”Ÿæˆå…ƒä¿¡æ¯

ä½œè€…ï¼šSean R. Liang
æ—¥æœŸï¼š2025-10-18
"""

import json
import os
import shutil
from datetime import datetime

def main():
    print("=" * 70)
    print("è¯è¡¨æœ€ç»ˆå½’æ¡£")
    print("=" * 70)
    print()
    
    base_dir = "data/vocabulary"
    
    # ===== 1. å°†v1.3è®¾ä¸ºæœ€ç»ˆç‰ˆæœ¬ =====
    print("[1] è®¾ç½®æœ€ç»ˆç‰ˆæœ¬...")
    
    v1_3_path = f"{base_dir}/rs_vocabulary_v1.3.json"
    final_path = f"{base_dir}/rs_vocabulary.json"
    
    if os.path.exists(v1_3_path):
        shutil.copy(v1_3_path, final_path)
        print(f"  âœ“ {v1_3_path} â†’ {final_path}")
    else:
        print(f"  âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ° {v1_3_path}")
        return
    
    # åŒæ ·å¤„ç†coverage report
    coverage_v1_3 = f"{base_dir}/coverage_report_v1.3.json"
    coverage_final = f"{base_dir}/coverage_report.json"
    
    if os.path.exists(coverage_v1_3):
        shutil.copy(coverage_v1_3, coverage_final)
        print(f"  âœ“ {coverage_v1_3} â†’ {coverage_final}")
    
    print()
    
    # ===== 2. åˆ›å»ºå½’æ¡£ç›®å½• =====
    print("[2] åˆ›å»ºå½’æ¡£ç›®å½•...")
    
    archive_dir = f"{base_dir}/archive"
    os.makedirs(archive_dir, exist_ok=True)
    print(f"  âœ“ {archive_dir}")
    print()
    
    # ===== 3. ç§»åŠ¨ä¸­é—´ç‰ˆæœ¬åˆ°å½’æ¡£ =====
    print("[3] å½’æ¡£ä¸­é—´ç‰ˆæœ¬...")
    
    files_to_archive = [
        "rs_vocabulary_v1.0_backup.json",
        "rs_vocabulary_v1.1_backup.json",
        "rs_vocabulary_v1.2_backup.json",
        "rs_vocabulary_v1.1.json",
        "rs_vocabulary_v1.2.json",
        "coverage_report_v1.2.json",
        "revision_log.txt",
        "revision_log_v1.3.txt",
    ]
    
    archived_count = 0
    for filename in files_to_archive:
        src = f"{base_dir}/{filename}"
        if os.path.exists(src):
            dst = f"{archive_dir}/{filename}"
            shutil.move(src, dst)
            print(f"  âœ“ å½’æ¡£ï¼š{filename}")
            archived_count += 1
    
    print(f"\n  å…±å½’æ¡£ {archived_count} ä¸ªæ–‡ä»¶")
    print()
    
    # ===== 4. ç”Ÿæˆç‰ˆæœ¬å†å²å…ƒä¿¡æ¯ =====
    print("[4] ç”Ÿæˆç‰ˆæœ¬å†å²å…ƒä¿¡æ¯...")
    
    # è¯»å–æœ€ç»ˆç‰ˆæœ¬
    with open(final_path, 'r', encoding='utf-8') as f:
        final_vocab = json.load(f)
    
    # è¯»å–è¦†ç›–ç‡æŠ¥å‘Š
    with open(coverage_final, 'r', encoding='utf-8') as f:
        coverage = json.load(f)
    
    # ç”Ÿæˆå…ƒä¿¡æ¯
    metadata = {
        "vocabulary_metadata": {
            "version": "1.3 (final)",
            "creation_date": "2025-10-18",
            "author": "Sean R. Liang",
            "description": "Three-granularity vocabulary for Remote Sensing image-text retrieval",
            "optimization_target": "Soft rewriting with RL-based semantic control (no LVLM)",
            "total_words": len(final_vocab['object']) + len(final_vocab['scene']) + len(final_vocab['layout']),
            "granularities": {
                "object": {
                    "count": len(final_vocab['object']),
                    "description": "Specific objects and landforms",
                    "examples": final_vocab['object'][:10]
                },
                "scene": {
                    "count": len(final_vocab['scene']),
                    "description": "Scene categories and attributes",
                    "examples": final_vocab['scene'][:10]
                },
                "layout": {
                    "count": len(final_vocab['layout']),
                    "description": "Spatial relations",
                    "examples": final_vocab['layout'][:10]
                }
            }
        },
        "coverage_statistics": {
            "content_word_coverage": coverage['coverage_rate_content'],
            "all_token_coverage": coverage['coverage_rate_all'],
            "total_captions_analyzed": 56485,
            "datasets": ["RSICD", "RSITMD"],
            "evaluation_date": "2025-10-18",
            "quality_rating": "Excellent (â‰¥70%)"
        },
        "version_history": {
            "v1.0": {
                "date": "2025-10-18",
                "changes": "Initial construction from RSICD+RSITMD corpus",
                "word_count": {"object": 187, "scene": 172, "layout": 50, "total": 409}
            },
            "v1.1": {
                "date": "2025-10-18",
                "changes": "Manual review and corrections (removed abstract words, added spatial terms)",
                "word_count": {"object": 166, "scene": 172, "layout": 53, "total": 391}
            },
            "v1.2": {
                "date": "2025-10-18",
                "changes": "High-frequency noun supplementation (singular forms + compound facilities)",
                "word_count": {"object": 182, "scene": 172, "layout": 53, "total": 407},
                "coverage": {"content_word": 72.73}
            },
            "v1.3": {
                "date": "2025-10-18",
                "changes": "Optimization for soft rewriting + RL (added area/farm/corner/block/district/wharf/lawn/vegetation in Object; circle/oval/triangular/khaki/empty in Scene; row in Layout)",
                "word_count": {"object": 190, "scene": 177, "layout": 54, "total": 421},
                "coverage": {"content_word": 75.45},
                "status": "FINAL"
            }
        },
        "usage_instructions": {
            "loading": "import json; vocab = json.load(open('data/vocabulary/rs_vocabulary.json'))",
            "granularities": {
                "object": "vocab['object']  # 190 words",
                "scene": "vocab['scene']   # 177 words",
                "layout": "vocab['layout']  # 54 words"
            },
            "applications": [
                "Soft rewriting with BERT MLM",
                "RL-based semantic control",
                "MoE text encoder routing",
                "Granularity-aware caption augmentation"
            ]
        },
        "file_structure": {
            "production": {
                "rs_vocabulary.json": "Main vocabulary file (v1.3)",
                "coverage_report.json": "Coverage analysis report",
                "METADATA.json": "This file"
            },
            "archive": {
                "location": "data/vocabulary/archive/",
                "contents": "All intermediate versions (v1.0, v1.1, v1.2) and legacy files"
            },
            "scripts": {
                "location": "scripts/",
                "files": [
                    "build_rs_vocabulary.py - Initial construction",
                    "check_vocabulary_coverage.py - Coverage analysis tool v2.0",
                    "fix_vocabulary.py - v1.0â†’v1.1 corrections",
                    "update_vocabulary_v1.2.py - v1.1â†’v1.2 upgrade",
                    "update_vocabulary_v1.3.py - v1.2â†’v1.3 upgrade"
                ]
            }
        }
    }
    
    metadata_path = f"{base_dir}/METADATA.json"
    with open(metadata_path, 'w', encoding='utf-8') as f:
        json.dump(metadata, f, indent=2, ensure_ascii=False)
    
    print(f"  âœ“ {metadata_path}")
    print()
    
    # ===== 5. ç”ŸæˆREADME =====
    print("[5] ç”ŸæˆREADME...")
    
    readme_content = """# é¥æ„Ÿä¸‰å±‚è¯­ä¹‰è¯è¡¨ (Remote Sensing Three-Granularity Vocabulary)

**ç‰ˆæœ¬**: v1.3 (Final)  
**æ—¥æœŸ**: 2025-10-18  
**ä½œè€…**: Sean R. Liang

## ğŸ“Š æ¦‚è§ˆ

æœ¬è¯è¡¨ä¸ºé¥æ„Ÿå›¾åƒ-æ–‡æœ¬æ£€ç´¢ä»»åŠ¡è®¾è®¡ï¼ŒåŒ…å«ä¸‰ä¸ªè¯­ä¹‰ç²’åº¦ï¼š

| ç²’åº¦ | è¯æ•° | æè¿° | ç¤ºä¾‹ |
|------|------|------|------|
| **Object** | 190 | åœ°ç‰©/è®¾æ–½ | buildings, trees, cars, airport, stadium |
| **Scene** | 177 | åœºæ™¯/å±æ€§ | residential, dense, green, circular, large |
| **Layout** | 54 | ç©ºé—´å…³ç³» | near, beside, surrounded, between, row |
| **æ€»è®¡** | **421** | | |

## âœ… è´¨é‡æŒ‡æ ‡

- **å†…å®¹è¯è¦†ç›–ç‡**: **75.45%** ğŸŸ© (ä¼˜ç§€)
- **All Tokenè¦†ç›–ç‡**: 49.21%
- **è®­ç»ƒè¯­æ–™**: RSICD (39,310æ¡) + RSITMD (17,175æ¡)
- **è´¨é‡è¯„çº§**: ç ”ç©¶çº§/å¯å‘è¡¨çº§

## ğŸ“ æ–‡ä»¶è¯´æ˜

### ç”Ÿäº§æ–‡ä»¶

```
data/vocabulary/
â”œâ”€â”€ rs_vocabulary.json           # â­ ä¸»è¯è¡¨ï¼ˆä½¿ç”¨è¿™ä¸ªï¼‰
â”œâ”€â”€ coverage_report.json         # è¦†ç›–ç‡åˆ†ææŠ¥å‘Š
â”œâ”€â”€ METADATA.json               # ç‰ˆæœ¬å†å²ä¸å…ƒä¿¡æ¯
â””â”€â”€ README.md                   # æœ¬æ–‡æ¡£
```

### å½’æ¡£æ–‡ä»¶

```
data/vocabulary/archive/
â”œâ”€â”€ rs_vocabulary_v1.0_backup.json
â”œâ”€â”€ rs_vocabulary_v1.1_backup.json
â”œâ”€â”€ rs_vocabulary_v1.2_backup.json
â”œâ”€â”€ rs_vocabulary_v1.1.json
â”œâ”€â”€ rs_vocabulary_v1.2.json
â””â”€â”€ ...ï¼ˆå…¶ä»–ä¸­é—´æ–‡ä»¶ï¼‰
```

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### Python

```python
import json

# åŠ è½½è¯è¡¨
with open('data/vocabulary/rs_vocabulary.json', 'r') as f:
    vocab = json.load(f)

# è®¿é—®ä¸‰ä¸ªç²’åº¦
object_words = vocab['object']   # 190ä¸ªåœ°ç‰©è¯
scene_words = vocab['scene']     # 177ä¸ªåœºæ™¯/å±æ€§è¯
layout_words = vocab['layout']   # 54ä¸ªç©ºé—´å…³ç³»è¯

# ç¤ºä¾‹ï¼šæ£€æŸ¥ä¸€ä¸ªè¯å±äºå“ªä¸ªç²’åº¦
word = "buildings"
if word in object_words:
    print(f"'{word}' is an Object word")
```

### åº”ç”¨åœºæ™¯

1. **è½¯æ”¹å†™ï¼ˆSoft Rewritingï¼‰**: ä½¿ç”¨BERT MLMåœ¨è¯å‘é‡ç©ºé—´è¿›è¡Œå¯å¾®æ”¹å†™
2. **RLè¯­ä¹‰æ§åˆ¶**: æ‰¹çº§å†³ç­–æ”¹å†™ç²’åº¦å’Œæ¸©åº¦å‚æ•°
3. **MoEæ–‡æœ¬ç¼–ç **: ä¸‰ç²’åº¦Expertçš„è½¯è·¯ç”±æƒé‡è®¡ç®—
4. **æ•°æ®å¢å¼º**: åŸºäºç²’åº¦çš„captionå˜æ¢

## ğŸ“ˆ ç‰ˆæœ¬å†å²

| ç‰ˆæœ¬ | æ—¥æœŸ | ä¸»è¦æ”¹åŠ¨ | è¯æ•° | è¦†ç›–ç‡ |
|------|------|----------|------|--------|
| v1.0 | 2025-10-18 | åˆå§‹æ„å»º | 409 | - |
| v1.1 | 2025-10-18 | äººå·¥æ£€éªŒä¿®æ­£ | 391 | - |
| v1.2 | 2025-10-18 | é«˜é¢‘è¯è¡¥å…… | 407 | 72.73% |
| **v1.3** | **2025-10-18** | **RLä¼˜åŒ–** | **421** | **75.45%** â­ |

## ğŸ”§ ç»´æŠ¤ä¸æ›´æ–°

å¦‚éœ€æ›´æ–°è¯è¡¨ï¼š

1. è¿è¡Œè¦†ç›–ç‡åˆ†æï¼š`python scripts/check_vocabulary_coverage.py`
2. æ£€æŸ¥æœªè¦†ç›–çš„é«˜é¢‘è¯
3. æ ¹æ®ä»»åŠ¡éœ€æ±‚å†³å®šæ˜¯å¦å¢è¡¥
4. æ›´æ–°ç‰ˆæœ¬å·å¹¶é‡æ–°å½’æ¡£

## ğŸ“ è”ç³»æ–¹å¼

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·è”ç³»ï¼šSean R. Liang

---

**æœ€åæ›´æ–°**: 2025-10-18
"""
    
    readme_path = f"{base_dir}/README.md"
    with open(readme_path, 'w', encoding='utf-8') as f:
        f.write(readme_content)
    
    print(f"  âœ“ {readme_path}")
    print()
    
    # ===== 6. æœ€ç»ˆæŠ¥å‘Š =====
    print("=" * 70)
    print("âœ… å½’æ¡£å®Œæˆï¼")
    print("=" * 70)
    print()
    print("æœ€ç»ˆæ–‡ä»¶ç»“æ„ï¼š")
    print()
    print("data/vocabulary/")
    print("â”œâ”€â”€ rs_vocabulary.json          â­ ä¸»è¯è¡¨ï¼ˆv1.3ï¼‰")
    print("â”œâ”€â”€ coverage_report.json        ğŸ“Š è¦†ç›–ç‡æŠ¥å‘Š")
    print("â”œâ”€â”€ METADATA.json              ğŸ“ å…ƒä¿¡æ¯")
    print("â”œâ”€â”€ README.md                  ğŸ“– ä½¿ç”¨è¯´æ˜")
    print("â”œâ”€â”€ rs_vocabulary_v1.3.json    ï¼ˆä¿ç•™ï¼‰")
    print("â”œâ”€â”€ coverage_report_v1.3.json  ï¼ˆä¿ç•™ï¼‰")
    print("â””â”€â”€ archive/                   ğŸ“¦ å½’æ¡£ç›®å½•")
    print("    â”œâ”€â”€ rs_vocabulary_v1.0_backup.json")
    print("    â”œâ”€â”€ rs_vocabulary_v1.1_backup.json")
    print("    â”œâ”€â”€ rs_vocabulary_v1.2_backup.json")
    print("    â””â”€â”€ ...ï¼ˆå…¶ä»–ä¸­é—´æ–‡ä»¶ï¼‰")
    print()
    print(f"è¯è¡¨ç»Ÿè®¡ï¼š")
    print(f"  - Object: {len(final_vocab['object'])} è¯")
    print(f"  - Scene: {len(final_vocab['scene'])} è¯")
    print(f"  - Layout: {len(final_vocab['layout'])} è¯")
    print(f"  - æ€»è®¡: {len(final_vocab['object']) + len(final_vocab['scene']) + len(final_vocab['layout'])} è¯")
    print()
    print(f"è´¨é‡æŒ‡æ ‡ï¼š")
    print(f"  - å†…å®¹è¯è¦†ç›–ç‡: {coverage['coverage_rate_content']:.2f}% ğŸŸ©")
    print(f"  - è´¨é‡è¯„çº§: ä¼˜ç§€")
    print()


if __name__ == "__main__":
    main()

